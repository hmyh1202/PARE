#!/bin/bash
#PBS -l nodes=1:ppn=4

<<"copyright_info"
randomNfrAna: determine nfr dip for random nucleosome free regions using histone marks (two replicates)
Copyright (C) 2015  Sachin Pundhir (pundhir@binf.ku.dk)

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
copyright_info

OUTDIR="nfr_random";
GENOME="mm9"
SHUFFLECOUNT=100000
MAX_FAILED_SHUFFLE_ATTEMPT=100

#### usage ####
usage() {
	echo Program: "randomNfrAna (determine nfr dip for random nucleosome free regions using histone marks (two replicates))"
	echo Author: BRIC, University of Copenhagen, Denmark
	echo Version: 1.0
	echo Contact: pundhir@binf.ku.dk
	echo "Usage: randomNfrAna -i <file> -k <file> -l <file> [OPTIONS]"
	echo "Options:"
	echo " -i <file>   [mapped read file(s) in BAM format]"
    echo "             [if multiple, please separate them by a comma]"
	echo " -k <file>   [optimal histone peaks region (regionPeak file)]"
	echo " -l <file>   [nfr file created by nfrAna script]"
    echo "[OPTIONS]"
    echo " -o <dir>    [output directory to store results (default: ./nfr_random)"
    echo " -p <int>    [number of processors to use (run in parallel)]"
    echo " -m <string> [genome (default: mm9)]"
    echo " -f <file>   [random NFRs should fall within these regions]"
    echo " -n <int>    [total number of random NFRs (default: 100000)]"
    echo " -c <int>    [extend 3' end of reads by input number of bases]"
    echo "             [if multiple, please separate them by a comma]"
    echo " -x <int>    [maximum limit of failed shuffle attempts before hard exit (default: 100)]"
	echo " -h          [help]"
	echo
	exit 0
}

#### parse options ####
while getopts i:k:l:o:p:m:f:n:c:x:h ARG; do
	case "$ARG" in
		i) BAMFILEs=$OPTARG;;
		k) PEAKREGION=$OPTARG;;
		l) NFRREGION=$OPTARG;;
        o) OUTDIR=$OPTARG;;
        p) PARALLEL=$OPTARG;;
        m) GENOME=$OPTARG;;
        f) INCLREGION=$OPTARG;;
        n) SHUFFLECOUNT=$OPTARG;;
        c) EXTENDs=$OPTARG;;
        x) MAX_FAILED_SHUFFLE_ATTEMPT=$OPTARG;;
		h) HELP=1;;
	esac
done

## usage, if necessary file and directories are given/exist
if [ -z "$BAMFILEs" -o ! -f "$PEAKREGION" -o ! "$NFRREGION" -o "$HELP" ]; then
	usage
fi

###################
#helperfunction
function wait_for_jobs_to_finish {
    for job in `jobs -p`
    do
        echo $job
        wait $job
    done
    echo $1
}
###############

echo -n "Determine number of input bam files (`date`).. "
oIFS=$IFS
IFS=","
BAMFILEa=($BAMFILEs)
IFS=$oIFS
if [ -z "$EXTENDs" ]; then
    for(( i=0; i<${#BAMFILEa[@]}; i++ )); do
        EXTENDs="$EXTENDs,0"
    done
    EXTENDs=$(echo $EXTENDs | perl -ane '$_=~s/^\,//g; print $_;')
fi
IFS=","
BAMFILEa=($BAMFILEs)
EXTENDa=($EXTENDs)
IFS=$oIFS
echo "done"

echo -n "Create directory structure.. "
if [ ! -d "$OUTDIR" ]; then
    mkdir $OUTDIR
    mkdir $OUTDIR/parallel
fi
echo "done"

echo -n "Populating files based on input genome ($GENOME)... "
GENOME_FILE=$(initialize_genome -i $PAREPATH/data/annotations/GENOME_FILE -g $GENOME)
GENOME_FILE=$PAREPATH/data/annotations/$GENOME_FILE
if [ ! -f "$GENOME_FILE" ]; then
    echo
    echo "computation for $GENOME is not feasible yet"
    echo "please add the chromosome size file for $GENOME at $PAREPATH/data/annotations"
    echo "also update the $PAREPATH/data/annotations/GENOME_FILE"
    echo
    usage
fi
echo done

## print header with choosen parameters
echo "#input BAM file(s): $BAMFILEs
#input histone peak region file: $PEAKREGION
#input NFR region file: $NFRREGION
#output directory: $OUTDIR
#reference genome: $GENOME
#regions within which to include random regions: $INCLREGION
#extend 3' end of reads: $EXTENDs" > $OUTDIR/PARAMETERS

## index bam files and estimate size factors
echo -n "Create index of input BAM files.. "
for(( i=0; i<${#BAMFILEa[@]}; i++ )); do
    if [ ! -e "${BAMFILEa[$i]}.bai" ]; then
        samtools index ${BAMFILEa[$i]}
    fi
done
echo "done"

echo -n "Compute size factor for each replicate.. "
if [ ${#BAMFILEa[@]} -gt 1 ]; then
    if [ ! -e "$OUTDIR/sizeFactorCount" ]; then
        estimateSizeFactor.pl -o b -b $BAMFILEs -x $PEAKREGION -r $OUTDIR/sizeFactorCount -p $PAREPATH/share/R/
    fi

    if [ ! -e "$OUTDIR/sizeFactor" ]; then
        estimateSizeFactor.pl -o c -r $OUTDIR/sizeFactorCount > $OUTDIR/sizeFactor -p $PAREPATH/share/R/
    fi
else
    touch $OUTDIR/sizeFactorCount
    perl -e 'print "'${BAMFILEa[0]}'\t1\n";' > $OUTDIR/sizeFactor
fi
echo "done"

echo -n "Retrieve size factors to normalize the expression of reads... "
SIZEFACTORa=($(cut -f 2 $OUTDIR/sizeFactor));
SIZEFACTORs=$(printf ",%s" "${SIZEFACTORa[@]}");
SIZEFACTORs=$(echo $SIZEFACTORs | perl -ane '$_=~s/^\,//g; print $_;')
echo "done"

## remove shuffled NFR file, if exists
if [ -f "$OUTDIR/RANDOM_NFRREGION.BED" ]; then
    rm $OUTDIR/RANDOM_NFRREGION.BED
fi

echo -n "determine increment factor to create random NFRs "
readarray -t ARR_NFRREGION < $NFRREGION;

INCREMENT_FACTOR=`perl -e '$frac='$SHUFFLECOUNT'/'${#ARR_NFRREGION[@]}'; if($frac>1) { print "2"; } else { print "1"; }'`;
echo "(increment factor: $INCREMENT_FACTOR).. done";

echo -n "check if enough background regions are available.. "
readarray -t ARR_INCLREGION < $INCLREGION;
INCLREGION_FACTOR=`perl -e '$frac='$SHUFFLECOUNT'/'${#ARR_INCLREGION[@]}'; printf("%0.0f", $frac);'`;
if [ "$SHUFFLECOUNT" -gt 10000 -a "$INCLREGION_FACTOR" -gt 20 ]; then
    echo "too few regions (N=${#ARR_INCLREGION[@]}) in $INCLREGION for finding $SHUFFLECOUNT shuffled regions.. exiting.. "
    exit 
fi
echo "done"

echo -n "create random NFR regions having length distribution similar to predicted ones.. "
SEED=1
FAIL_COUNT=0
if [ "$INCREMENT_FACTOR" -gt 1 ]; then
    #for (( i=0; i<$SHUFFLECOUNT; i+=${#ARR_NFRREGION[@]} )); do
    for (( i=0; i<$(( SHUFFLECOUNT*2 )); i+=${#ARR_NFRREGION[@]} )); do
        #if [ -f "$OUTDIR/RANDOM_NFRREGION.BED" -a "$(cat $OUTDIR/RANDOM_NFRREGION.BED 2>/dev/null | wc -l)" -gt "$SHUFFLECOUNT" ]; then
        #    break
        if [ -s "$OUTDIR/RANDOM_NFRREGION.BED" ]; then
            if [ -z "$INCLREGION" ]; then
                bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE -excl $OUTDIR/RANDOM_NFRREGION.BED >> $OUTDIR/RANDOM_NFRREGION.BED
            else
                #bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE -incl $INCLREGION -excl $OUTDIR/RANDOM_NFRREGION.BED >> $OUTDIR/RANDOM_NFRREGION.BED
                bedtools intersect -a <(bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE -incl $INCLREGION -excl $OUTDIR/RANDOM_NFRREGION.BED) -b $INCLREGION -f 1.0 >> $OUTDIR/RANDOM_NFRREGION.BED
                if [ $? -ne 0 ]; then FAIL_COUNT=$(echo $FAIL_COUNT | perl -ane '$count=$_+1; print "$count";'); fi
            fi
        else
            if [ -z "$INCLREGION" ]; then
                bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE > $OUTDIR/RANDOM_NFRREGION.BED
            else
                #bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE -incl $INCLREGION > $OUTDIR/RANDOM_NFRREGION.BED
                bedtools intersect -a <(bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE -incl $INCLREGION) -b $INCLREGION -f 1.0 > $OUTDIR/RANDOM_NFRREGION.BED
            fi
        fi
        SEED=$(( SEED+10 ))

        ## exit if fail count exceeds 100 times
        if [ "$FAIL_COUNT" -gt "$MAX_FAILED_SHUFFLE_ATTEMPT" ]; then
            echo "failed counts.. $FAIL_COUNT"
            echo "exceeded maximum limit of failed shuffle attempts ($MAX_FAILED_SHUFFLE_ATTEMPT).. exiting.. "
            exit;
        fi

    done
<<"COMMENT"
    for (( i=0; i<${#ARR_NFRREGION[@]}; i++ )); do
        UPSTREAM_LENGTH=`echo ${ARR_NFRREGION[i]} | cut -f 10 -d " "`;
        DOWNSTREAM_LENGTH=`echo ${ARR_NFRREGION[i]} | cut -f 12 -d " "`;
        NFR_LENGTH=`echo ${ARR_NFRREGION[i]} | cut -f 14 -d " "`;

        #echo -e "$UPSTREAM_LENGTH\t$DOWNSTREAM_LENGTH\t$NFR_LENGTH\t$INCREMENT_FACTOR";
        if [ -s "$OUTDIR/RANDOM_NFRREGION.BED" ]; then
            bedtools random -l $NFR_LENGTH -n $((INCREMENT_FACTOR*2)) -g $GENOME_FILE | bedtools shuffle -noOverlapping -i stdin -g $GENOME_FILE -incl $INCLREGION -excl $OUTDIR/RANDOM_NFRREGION.BED | head -n $INCREMENT_FACTOR | perl -ane 'chomp($_); print "$_\t'$UPSTREAM_LENGTH'\t'$DOWNSTREAM_LENGTH'\n";' >> $OUTDIR/RANDOM_NFRREGION.BED
        else
            bedtools random -l $NFR_LENGTH -n $INCREMENT_FACTOR -g $GENOME_FILE | perl -ane 'chomp($_); print "$_\t'$UPSTREAM_LENGTH'\t'$DOWNSTREAM_LENGTH'\n";' > $OUTDIR/RANDOM_NFRREGION.BED
        fi
    done
COMMENT
    bedtools sample -seed 1 -n $SHUFFLECOUNT -i $OUTDIR/RANDOM_NFRREGION.BED | cut -f 1,2,3,4,5,6,10,12 > $OUTDIR/RANDOM_NFRREGION.BED.tmp
    #intersectBed -a $OUTDIR/RANDOM_NFRREGION.BED -b $OUTDIR/RANDOM_NFRREGION.BED -c | perl -ane 'if($F[14]==1) { print $_; }' | bedtools sample -n $SHUFFLECOUNT -i stdin | cut -f 1,2,3,4,5,6,10,12 > $OUTDIR/RANDOM_NFRREGION.BED.tmp 
    mv $OUTDIR/RANDOM_NFRREGION.BED.tmp $OUTDIR/RANDOM_NFRREGION.BED
else
    if [ -z "$INCLREGION" ]; then
        bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE | bedtools sample -n $SHUFFLECOUNT -i stdin | cut -f 1,2,3,4,5,6,10,12 > $OUTDIR/RANDOM_NFRREGION.BED
    else
        bedtools shuffle -seed $SEED -noOverlapping -i $NFRREGION -g $GENOME_FILE -incl $INCLREGION | bedtools sample -n $SHUFFLECOUNT -i stdin | cut -f 1,2,3,4,5,6,10,12 > $OUTDIR/RANDOM_NFRREGION.BED
    fi
fi
echo "done"

## remove nfr dip score file, if exists
if [ -f "$OUTDIR/RANDOM_NFRREGION.BED.SCORE" ]; then
    rm $OUTDIR/RANDOM_NFRREGION.BED.SCORE
fi

echo -n "compute nfr dip for random NFR regions.. "
if [ ! -z "$PARALLEL" ]; then
    rm -r $OUTDIR/parallel/x*
    indexBed.sh -i $OUTDIR/RANDOM_NFRREGION.BED -o $OUTDIR/parallel -x x

    #for file in `ls $OUTDIR/parallel/x*`; do
    #    #bed2nfrdip -i $file -j $BAMFILEs -k $SIZEFACTORs -e $EXTENDs -g $GENOME > $file.score &
    #    ## NOW USES V2 (uses bedtools multicov - faster)
    #    bed2nfrdipV2 -i $file -j $BAMFILEs -k $SIZEFACTORs -e $EXTENDs -g $GENOME -v | perl -ane 'print "$F[0]\t$F[1]\t$F[2]\t".$F[scalar(@F)-1]."\n";' > $file.score &
    #done
    #wait

    ls $OUTDIR/parallel/x* | grep -v score | parallel -j $PARALLEL 'bed2nfrdipV2 -i '{}' -j '$BAMFILEs' -k '$SIZEFACTORs' -e '$EXTENDs' -g '$GENOME' -v > '{}'.score'

    intersectBed -a <(cat $OUTDIR/parallel/x*score) -b $NFRREGION -v > $OUTDIR/RANDOM_NFRREGION.BED.SCORE
else
    #bed2nfrdip -i $OUTDIR/RANDOM_NFRREGION.BED -j $BAMFILEs -k $SIZEFACTORs -e $EXTENDs -g $GENOME > $OUTDIR/RANDOM_NFRREGION.BED.TMP &
    ## NOW USES V2 (uses bedtools multicov - faster)
    bed2nfrdipV2 -i $OUTDIR/RANDOM_NFRREGION.BED -j $BAMFILEs -k $SIZEFACTORs -e $EXTENDs -g $GENOME -v > $OUTDIR/RANDOM_NFRREGION.BED.TMP
    intersectBed -a $OUTDIR/RANDOM_NFRREGION.BED.TMP -b $NFRREGION -v > $OUTDIR/RANDOM_NFRREGION.BED.SCORE
    rm $OUTDIR/RANDOM_NFRREGION.BED.TMP
fi
echo "done"
